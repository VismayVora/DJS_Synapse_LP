{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C8KlsCFL1tvs"
   },
   "source": [
    "# Task 1\n",
    "#### Week 1 (Learning Period Synapse)\n",
    "###### pandas, numpy, matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24070,
     "status": "ok",
     "timestamp": 1632724381141,
     "user": {
      "displayName": "Amay Gada",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhIegWflm0DVHy8h-sj9l7nvh_87WZPEby6oqxqjw=s64",
      "userId": "18318224108445437394"
     },
     "user_tz": -330
    },
    "id": "wcGii-p723dl",
    "outputId": "c3c08099-f6ef-4352-d716-be75fb277dd2"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b79d998bf33d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/gdrive\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/gdrive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m6HJFwYI9U55"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ufinDlF2oH7"
   },
   "source": [
    "## 1. Import pandas, numpy and matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "V0KqGm1I2mx6"
   },
   "outputs": [],
   "source": [
    "#write code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "P0xumbaX27tR"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5dFTZvpm28n7"
   },
   "source": [
    "## 2. load the data \n",
    "<br> load the titanic dataset in a pandas dataframe <br> (download dataset from https://www.kaggle.com/c/titanic/data and store it in a folder called <b>\"syanpse_w1\"</b> in the root of your drive) <br>\n",
    "Note that you have to download the train and test csv files seperately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "executionInfo": {
     "elapsed": 1596,
     "status": "error",
     "timestamp": 1632806561598,
     "user": {
      "displayName": "Synapse Core",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gip0hd3Ps58SeJVlXZMjgdmz6n_nah5Hzl1ynjg=s64",
      "userId": "00506809504713929423"
     },
     "user_tz": -330
    },
    "id": "mY_Fol-u1qmi",
    "outputId": "e5413149-c574-4071-e1b0-208bea8de0ac"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/Users/Rajesh/Documents/MEGAsync/Synapse/Synapse_w1/train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-b47931efe3c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#write code to load train.csv and test.csv in dataframes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtrain_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mtest_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/Rajesh/Documents/MEGAsync/Synapse/Synapse_w1/train.csv'"
     ]
    }
   ],
   "source": [
    "#train_path = \"/content/gdrive/My Drive/synapse_w1/train.csv\"\n",
    "#test_path = \"/content/gdrive/My Drive/synapse_w1/test.csv\"\n",
    "\n",
    "train_path = \"C:/Users/Rajesh/Documents/MEGAsync/Synapse/Synapse_w1/train.csv\"\n",
    "test_path = \"C:/Users/Rajesh/Documents/MEGAsync/Synapse/Synapse_w1/test.csv\"\n",
    "\n",
    "#write code to load train.csv and test.csv in dataframes\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df = pd.read_csv(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "loyfFwFK1s6-"
   },
   "outputs": [],
   "source": [
    "#write code to show first five data entries of both dataframes\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d21HPJDrHFOk"
   },
   "outputs": [],
   "source": [
    "test_df.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eAe9H4ub-9TB"
   },
   "source": [
    "## 3. Exploratory Data Analysis\n",
    "Exploratory data analysis is a very important part of ML as it helps you understand the data you are dealing with <br>\n",
    "<br>\n",
    "(we will be working on the train dataframe in this task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7n5NzvIOAH1G"
   },
   "source": [
    "### 3.a. overview of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dIl7EiGEBjPL"
   },
   "source": [
    " - write code to list the columns in your dataframe (each column on new line as visibility is important)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "jgGpmmk4BNpf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId\n",
      "Survived\n",
      "Pclass\n",
      "Name\n",
      "Sex\n",
      "Age\n",
      "SibSp\n",
      "Parch\n",
      "Ticket\n",
      "Fare\n",
      "Cabin\n",
      "Embarked\n"
     ]
    }
   ],
   "source": [
    "columns_array = train_df.columns\n",
    "columns_list = list(columns_array)\n",
    "print(*columns_list, sep = \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BbtlcScEBkwG"
   },
   "source": [
    " - write a function that returns the number of rows and columns in the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "huYZDIdW87BM"
   },
   "outputs": [],
   "source": [
    "#write code here (print values as well)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tFWvBxGvCR5M"
   },
   "source": [
    " - use the info() method of pandas dataframe to print the info related to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "oDGygTjuAhtf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JtEy2fQuCfic"
   },
   "source": [
    " - use the describe() method of pandas dataframe to print the statistical description of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "HmAzuSpcCfAC"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A9e7GcsJC_ww"
   },
   "source": [
    " - Find all columns that have unique values. (example : the Gender column has 2 unique values Male and Female) <br>\n",
    "\n",
    " - if the columns have finite unique values, then add them in a dictionary of lists and print it <br>\n",
    "<br>\n",
    "dictionary should look like : <br>\n",
    "<t>{<br>&nbsp;&nbsp; \"Gender\" : [\"Male\", \"Female\"],<br>&nbsp;&nbsp; \"Col2\" : [\"unique1\", \"unique2\"],<br>&nbsp;&nbsp;&nbsp;&nbsp;.<br>&nbsp;&nbsp;&nbsp;&nbsp;.<br>&nbsp;&nbsp;&nbsp;&nbsp;.<br>}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SvWOT_pKDbdu"
   },
   "outputs": [],
   "source": [
    "#write code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CBMXRkJTHyWL"
   },
   "outputs": [],
   "source": [
    "train_df."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V1OdlEqXHzMC"
   },
   "source": [
    "### 3.b. Visualizing hidden Details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "De37jtciIY7F"
   },
   "source": [
    "##### Aim is to find relationship between Title and Survival rate\n",
    "- print the <b>name</b> column of the data<br>\n",
    "- notice that the word after the first comma encapsulates the title of the person (Mr., Mrs, etc)\n",
    "- extract the title using regular expression (help given below in the code)\n",
    "- store the title in a new column in the dataframe. Name the column : <b>Title</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "URnLEQP-EsXA"
   },
   "outputs": [],
   "source": [
    "#write code here (for regex help refer next code cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 415,
     "status": "ok",
     "timestamp": 1632728270660,
     "user": {
      "displayName": "Amay Gada",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhIegWflm0DVHy8h-sj9l7nvh_87WZPEby6oqxqjw=s64",
      "userId": "18318224108445437394"
     },
     "user_tz": -330
    },
    "id": "X62p2RoZIp6U",
    "outputId": "4d8f881f-c018-4ca4-fae1-f1dc83cc30b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: <re.Match object; span=(10, 15), match='Miss.'>\n",
      "pattern found\n",
      "title: Miss\n"
     ]
    }
   ],
   "source": [
    "#regex example\n",
    "import re\n",
    "\n",
    "name_eg = \"Petranec, Miss. Matilda\"\n",
    "title_search = re.search('(\\w+)\\.', name_eg) #the first argument is a pattern that we are looking for\n",
    "print(\"result:\", title_search) #this is the result we get after looking for the pattern\n",
    "if title_search:\n",
    "  print(\"pattern found\") #pattern found printed if a pattern like above is found\n",
    "  title = title_search.group(1) #extracting the pattern found by regular expression (title here)\n",
    "  print(\"title:\", title) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5ZMsfu5HKYbU"
   },
   "outputs": [],
   "source": [
    "#show the new dataframe with \"Title\" column here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bLHjnfQ3O7Nf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xQBmJI2eM5KT"
   },
   "source": [
    "- write code to get unique values from the title column\n",
    "- use the unique titles to find the number of people who survived (1) and number of people who did not (0) for each title. <b>num_survived/total</b> will give the survival rate for that title\n",
    "- make a new dataframe called <b>SR_df</b> and add the survival rates corresponding to titles in it<br><br>\n",
    "you may write a function for the above.<br><br>\n",
    "expected output : <br>\n",
    "Mr &nbsp;&nbsp; 0.679392<br>\n",
    "Capt &nbsp;&nbsp; 0.1245<br>\n",
    "&nbsp;&nbsp;.<br>\n",
    "&nbsp;&nbsp;.<br>\n",
    "&nbsp;&nbsp;.<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HYHZxu-YO-NJ"
   },
   "outputs": [],
   "source": [
    "#write code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eftv29NFPJzr"
   },
   "outputs": [],
   "source": [
    "#show the new dataframe SR_df here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cxczSuKiPr5u"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Olnh97qqO-tZ"
   },
   "source": [
    "- use SR_df to plot a bar graph for survival rate vs Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QYmrVku9MPdT"
   },
   "outputs": [],
   "source": [
    "#write code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xrIVW_mHQPJX"
   },
   "source": [
    "This brings us to the end of EDA. <br>\n",
    "You may feel free to do more exploratry analysis.<br>\n",
    "The aim of this notebook is not to point out every small detail but to give you an overview and guide you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qzpcPY_vRfNM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2tImb-hXsXmI"
   },
   "source": [
    "## 4. Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ah1dARlJsddI"
   },
   "source": [
    "- Make a pie chart to show the number of people who survived and number of people who did not\n",
    "- Make a pie chart to show the number of <b>Males</b> who survived and number of people who did not\n",
    "- Make a pie chart to show the number of <b>Females</b> who survived and number of people who did not\n",
    "<br><br>\n",
    "Note that all three charts must be visible in a single row (look into subplots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gaZyWEN5sXP6"
   },
   "outputs": [],
   "source": [
    "#write code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uYSmxfqEsjGo"
   },
   "source": [
    "- Find if money affected survival rate (fare and Pclass) \n",
    " - Make a bar graph showing Pclass vs survival rate\n",
    " - Make a KDE plot (use the sns library) and plot Fare based on the Survival (google away for this one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l3YP8H18si4G"
   },
   "outputs": [],
   "source": [
    "#write code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ekU_aa0Wsn6T"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NzSBvjqdRfiM"
   },
   "source": [
    "## 5. Preprocessing\n",
    "preprocessing is a very important step before we step into modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1_HLgWAZTD-2"
   },
   "source": [
    " - when we added the Title column in the datadframe, we did preprocessing on the existing data to extract relevant information. As we also tried to explore and understand the data using survival rate, we saw it under EDA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V-eJsxXrTuBJ"
   },
   "source": [
    "### 5.a. Removing unnecessary columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ij1QOguUT7nO"
   },
   "source": [
    " - The columns PassengerId and Ticket play no logical role in being related to the survival of a passenger. Hence we will remove them.\n",
    " - We will also remove the Name column as we have done <b>feature extraction</b> and obtained titles instead. (test set might have extra titles which are not in the train set. Think about how we would consider them. This however doesn't affect task 1's objective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lpLKo4YgMSKA"
   },
   "outputs": [],
   "source": [
    "#write code to remove unnecessary columns from the dataframe here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IwARq2gEaoYK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "63jou6PJaoqp"
   },
   "source": [
    "### 5.b. Nan analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qh6_TT42ay-x"
   },
   "source": [
    " - write code to find the percentage of Nans in each column and visualize it in a tabular format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F0V-qmTDUMAx"
   },
   "outputs": [],
   "source": [
    "#write code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2mqclVHla_ey"
   },
   "source": [
    " - remove any column having more than 50% Nans as they would be of no use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wN6LpxsKa-Zi"
   },
   "outputs": [],
   "source": [
    "#write code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YfPIbLBkbU8C"
   },
   "source": [
    " - Fill Nans in the Embark column with the statistical mode\n",
    " - Fill Nans in the Age column with it's statistical mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ht5Uxpb6a9SA"
   },
   "outputs": [],
   "source": [
    "#write code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ldZ-7Knyc7r1"
   },
   "source": [
    " - show the new Nan percentage vs column name table after filling and removing to make sure there are no Nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qalNu0Gvc6ih"
   },
   "outputs": [],
   "source": [
    "#write code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_aeWd33AepZi"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EQKtPBSSgUpN"
   },
   "source": [
    "### 5.c. Adding features to the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "daJuxRs4gcH9"
   },
   "source": [
    " - Read the kaggle link (titanic dataset) provided above and see what the two columns SibSP and Parch signify\n",
    " - Using that create a new column called <B>Family_members</b>\n",
    " - Fill it with the sum of SibSP and Parch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IZF7_Jfagbd_"
   },
   "outputs": [],
   "source": [
    "#write code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1jrABHyphdWg"
   },
   "source": [
    " - Now you may remove the two columns SibSP and Parch<br>\n",
    " It is important to remove them because they introduce multicollinearity in our dataset now as the new column Family_members is directly dependent on them.<br>\n",
    " Multicollinearity is deadly to linear models that we will look into later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aPf3p6WChc3g"
   },
   "outputs": [],
   "source": [
    "#write code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZoC97Umai-vg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Az401HQIi8FR"
   },
   "source": [
    "### 5.d. Scaling and Normalization\n",
    "we don't want to give undue advantage to a few columns (when training models), just because they have a numeric data that is larger in magnitude.<br>\n",
    "Therefore we scale all values down to a specific range or distribution\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8uXii3c6jx-4"
   },
   "source": [
    " - Columns to apply scaling on\n",
    "  - Age\n",
    "  - Fare\n",
    "  - Family_members\n",
    "\n",
    "- Although Pclass column is numeric, it contains classification data (only 1, 2 and 3). Therefore only continuous data like age, fare, etc needs to be normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NwDqNCcrlYtR"
   },
   "source": [
    " - Read about standardization and normalization in this link https://www.geeksforgeeks.org/normalization-vs-standardization/\n",
    " - apply the formulas given in the link above and scale/normalize the features that are supposed to be scaled\n",
    " - It is your choice to choose wether you choose to normalize or standardize a column. You will be able to make your choice after reading the link contents.\n",
    " - If you feel confused with the choice, then you can go ahead and directly normalize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9LzoSA42h_wv"
   },
   "outputs": [],
   "source": [
    "#write code here to normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C88SQvKkm-r8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8KXM4Xe0m-bj"
   },
   "source": [
    "### 5.e. One hot encoding\n",
    "Machine Learning models do not understand strings <br>\n",
    "They understand numbers<br>\n",
    "That is one of the reasons why we one hot encode few columns<br>\n",
    "\n",
    "- refer this link for more information : https://datagy.io/pandas-get-dummies/\n",
    "- you can use this or directly look into pandas get_dummies() method to implement this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1IIsD-KcpVBc"
   },
   "source": [
    "- columns to apply one_hot encoding on\n",
    " - Pclass\n",
    " - Sex\n",
    " - Title\n",
    " - Embarked\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y60WNgwLjrmn"
   },
   "outputs": [],
   "source": [
    "#write code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r4wogy53paiL"
   },
   "outputs": [],
   "source": [
    "#show the final dataframe here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QhGsnsY4puYz"
   },
   "source": [
    "End of Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wa1zcX8_pyk5"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Task1.ipynb",
   "provenance": [
    {
     "file_id": "104rkhBnX-dWZRNvhXt_bZ_PtX8-0uoRN",
     "timestamp": 1632739771478
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
